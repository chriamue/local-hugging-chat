version: '3'
services:

  nginx:
    image: nginx:latest
    ports:
      - "8000:80"
    volumes:
      - "./nginx.conf:/etc/nginx/conf.d/default.conf"
    depends_on:
      - chat-ui
      - text-generation-inference

  chat-ui-db:
    image: ghcr.io/huggingface/chat-ui-db:latest
    container_name: mongodb

  chat-ui:
    image: ghcr.io/huggingface/chat-ui:latest
    container_name: chat-ui
    environment:
      - MONGODB_URL=mongodb://mongodb:27017
    ports:
      - "3000:3000"
    depends_on:
      - chat-ui-db
      - text-generation-inference

  text-generation-inference:
    image: ghcr.io/huggingface/text-generation-inference:1.2-rocm
    command: ["--max-total-tokens", "3080", "--max-input-length", "3072", "--max-batch-prefill-tokens", "3080", "--quantize", "gptq", "--model-id", "mzbac/CodeLlama-34b-guanaco-gptq"]
    volumes:
      - ./models:/data
    container_name: text-generation-inference
    devices:
      - "/dev/kfd"
      - "/dev/dri"
    shm_size: 1g